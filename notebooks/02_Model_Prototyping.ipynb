{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95ccf824",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydotplus'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Needed for decision tree visualization\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpydotplus\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydotplus'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Needed for decision tree visualization\n",
    "import pydotplus\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0532671",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the cleaned dataset \n",
    "data_path = ('../data/processed/cleaned_happiness_data.csv')\n",
    "data_cleaned= pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4ec48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ccdd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variables\n",
    "features = data_cleaned.drop(['HappinessIndicator'], axis=1)\n",
    "target = data_cleaned['HappinessIndicator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5946c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0a542a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaf9241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf215519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02f995d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c1e334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the accuracy report\n",
    "print(\"Accuracy Score:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d900c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6c5972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and display the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23afb732",
   "metadata": {},
   "source": [
    "## Model Performance Summary\n",
    "\n",
    "Upon fitting the logistic regression model to the dataset, we observed an exceedingly high accuracy score of approximately 98.9%. The classification report yielded high precision, recall, and F1-scores across both classes, indicating the model's proficient performance in classifying individuals as \"happy\" or \"not happy.\" The following points detail the model's evaluation metrics:\n",
    "\n",
    "- **Precision**: Exceptionally high for both classes, suggesting a minimal rate of false positives.\n",
    "- **Recall**: Perfect for the \"not happy\" class, indicating no false negatives, and nearly perfect for the \"happy\" class.\n",
    "- **F1-Score**: Close to 1 for both classes, denoting an excellent balance between precision and recall.\n",
    "- **Support**: Reflects the balanced distribution of classes within the test dataset.\n",
    "\n",
    "The confusion matrix provided additional insights:\n",
    "\n",
    "- Correctly predicted \"not happy\" instances: 131\n",
    "- Correctly predicted \"happy\" instances: 140\n",
    "- False negatives: 3\n",
    "- False positives: 0\n",
    "\n",
    "### Interpretation and Recommendations\n",
    "\n",
    "The high accuracy and F1-scores suggest the logistic regression model is highly effective. However, such high performance could potentially be a sign of overfitting. It is crucial to validate the model's reliability through further testing and evaluation. Recommendations to ensure robustness and validity of the model include:\n",
    "\n",
    "1. **Cross-Validation**: To confirm consistency across various data subsets.\n",
    "2. **Feature Importance Analysis**: To understand the drivers of the model's decisions.\n",
    "3. **Testing More Complex Models**: Such as Random Forest or Gradient Boosting for comparative analysis.\n",
    "4. **Regularization Techniques**: To prevent overfitting and enhance model generalization.\n",
    "5. **Data Augmentation**: If data availability is limited, augmenting the dataset could improve model generalization.\n",
    "6. **Anomaly Detection**: To identify and rectify data points that disproportionately influence the model.\n",
    "7. **Domain Expert Consultation**: To align the model's predictions with expert knowledge.\n",
    "8. **External Validation**: To assess performance on an unseen dataset and ensure generalizability.\n",
    "\n",
    "These steps aim not only to potentially enhance model performance but to also affirm the reliability and applicability of the model to real-world scenarios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0937b68f",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c75a4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random forest classifier instance\n",
    "rf_model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879301e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b84f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions using the testing data\n",
    "rf_predictions = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593552e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the confusion matrix\n",
    "rf_cm = confusion_matrix(y_test, rf_predictions)\n",
    "rf_cm_df = pd.DataFrame(\n",
    "    rf_cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"]\n",
    ")\n",
    "\n",
    "# Calculating the accuracy score\n",
    "acc_score = accuracy_score(y_test, rf_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b9306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(rf_cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, rf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489ba258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and display the confusion matrix\n",
    "sns.heatmap(rf_cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b183f2e0",
   "metadata": {},
   "source": [
    "### Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85655d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the decision tree classifier instance\n",
    "decision_tree_model = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a6df9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "decision_tree_model = decision_tree_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7967ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions using the testing data\n",
    "decision_tree_predictions = decision_tree_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f491b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the confusion matrix\n",
    "dt_cm = confusion_matrix(y_test, decision_tree_predictions)\n",
    "dt_cm_df = pd.DataFrame(\n",
    "    dt_cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"]\n",
    ")\n",
    "\n",
    "# Calculating the accuracy score\n",
    "acc_score = accuracy_score(y_test, decision_tree_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b259a2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(dt_cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, decision_tree_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e931df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and display the confusion matrix\n",
    "sns.heatmap(dt_cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f43bc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DOT data\n",
    "dot_data = tree.export_graphviz(\n",
    "    decision_tree_model, out_file=None, feature_names=features.columns, class_names=[\"0\", \"1\"], filled=True\n",
    ")\n",
    "\n",
    "# Draw graph\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "\n",
    "# Show graph\n",
    "Image(graph.create_png())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
